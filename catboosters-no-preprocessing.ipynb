{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install kaggle\n!echo '{\"username\":\"gr4ceg\",\"key\":\"08da1952aa6a96f237cf1e4c73f05c26\"}' > kaggle.json\n!mkdir -p /root/.kaggle\n!mv kaggle.json /root/.kaggle\n!chmod 600 /root/.kaggle/kaggle.json\n!kaggle competitions download -c cs-480-2024-spring\n!unzip -q *.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom graphviz import Digraph\n\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\n\n# Example function to extract features from images using a pre-trained EfficientNet model\nfrom torchvision.models import efficientnet_b7\n\nimport numpy as np\nfrom tqdm import tqdm  # Import tqdm for the progress bar\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom catboost import CatBoostRegressor, Pool","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:20:43.594443Z","iopub.execute_input":"2024-08-13T10:20:43.595359Z","iopub.status.idle":"2024-08-13T10:20:43.601478Z","shell.execute_reply.started":"2024-08-13T10:20:43.595323Z","shell.execute_reply":"2024-08-13T10:20:43.600484Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv('/kaggle/working/data/train.csv')\n\nancillary_columns = train_data.columns[1:164]\nprint(ancillary_columns)\n\nlabel_columns = train_data.columns[164:]\nprint(label_columns)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:20:45.734942Z","iopub.execute_input":"2024-08-13T10:20:45.735313Z","iopub.status.idle":"2024-08-13T10:20:46.907720Z","shell.execute_reply.started":"2024-08-13T10:20:45.735284Z","shell.execute_reply":"2024-08-13T10:20:46.906801Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Index(['WORLDCLIM_BIO1_annual_mean_temperature',\n       'WORLDCLIM_BIO12_annual_precipitation',\n       'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n       'WORLDCLIM_BIO15_precipitation_seasonality',\n       'WORLDCLIM_BIO4_temperature_seasonality',\n       'WORLDCLIM_BIO7_temperature_annual_range',\n       'SOIL_bdod_0.5cm_mean_0.01_deg', 'SOIL_bdod_100.200cm_mean_0.01_deg',\n       'SOIL_bdod_15.30cm_mean_0.01_deg', 'SOIL_bdod_30.60cm_mean_0.01_deg',\n       ...\n       'VOD_X_1997_2018_multiyear_mean_m03',\n       'VOD_X_1997_2018_multiyear_mean_m04',\n       'VOD_X_1997_2018_multiyear_mean_m05',\n       'VOD_X_1997_2018_multiyear_mean_m06',\n       'VOD_X_1997_2018_multiyear_mean_m07',\n       'VOD_X_1997_2018_multiyear_mean_m08',\n       'VOD_X_1997_2018_multiyear_mean_m09',\n       'VOD_X_1997_2018_multiyear_mean_m10',\n       'VOD_X_1997_2018_multiyear_mean_m11',\n       'VOD_X_1997_2018_multiyear_mean_m12'],\n      dtype='object', length=163)\nIndex(['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean',\n       'X3112_mean'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split features and targets\nimage_paths = 'data/train_images/' + train_data.iloc[:, 0].astype(str) + '.jpeg'\n\nancillary_data = train_data.iloc[:, 1:164]\nlabels = train_data.iloc[:, 164:]\n\n# Split the data into training and validation sets\ntrain_ancillary, val_ancillary, train_labels, val_labels, train_images, val_images = train_test_split(\n    ancillary_data, labels, image_paths, test_size=0.20, random_state=42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T10:20:50.289023Z","iopub.execute_input":"2024-08-13T10:20:50.289781Z","iopub.status.idle":"2024-08-13T10:20:50.393237Z","shell.execute_reply.started":"2024-08-13T10:20:50.289749Z","shell.execute_reply":"2024-08-13T10:20:50.392407Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_images = train_images.to_numpy()\nval_images = val_images.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:20:52.085348Z","iopub.execute_input":"2024-08-13T10:20:52.086240Z","iopub.status.idle":"2024-08-13T10:20:52.091236Z","shell.execute_reply.started":"2024-08-13T10:20:52.086200Z","shell.execute_reply":"2024-08-13T10:20:52.090129Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(f\"Training ancillary data: {train_ancillary.shape}\")\nprint(f\"Validation ancillary data: {val_ancillary.shape}\")\nprint(f\"Training labels: {train_labels.shape}\")\nprint(f\"Validation labels: {val_labels.shape}\")\nprint(f\"Training images: {len(train_images)}\")\nprint(f\"Validation images: {len(val_images)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:20:53.587001Z","iopub.execute_input":"2024-08-13T10:20:53.587395Z","iopub.status.idle":"2024-08-13T10:20:53.594316Z","shell.execute_reply.started":"2024-08-13T10:20:53.587367Z","shell.execute_reply":"2024-08-13T10:20:53.593182Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Training ancillary data: (34690, 163)\nValidation ancillary data: (8673, 163)\nTraining labels: (34690, 6)\nValidation labels: (8673, 6)\nTraining images: 34690\nValidation images: 8673\n","output_type":"stream"}]},{"cell_type":"code","source":"print(image_paths.head())\nprint(ancillary_data[:5])\nprint(labels[:5])","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:20:55.335692Z","iopub.execute_input":"2024-08-13T10:20:55.336602Z","iopub.status.idle":"2024-08-13T10:20:55.355375Z","shell.execute_reply.started":"2024-08-13T10:20:55.336569Z","shell.execute_reply":"2024-08-13T10:20:55.354445Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"0    data/train_images/101801795.jpeg\n1    data/train_images/115813315.jpeg\n2    data/train_images/173551949.jpeg\n3    data/train_images/148811120.jpeg\n4    data/train_images/195108876.jpeg\nName: id, dtype: object\n   WORLDCLIM_BIO1_annual_mean_temperature  \\\n0                               21.478968   \n1                               26.927639   \n2                               27.336945   \n3                               25.558649   \n4                               25.204723   \n\n   WORLDCLIM_BIO12_annual_precipitation  \\\n0                            772.404785   \n1                           1456.733276   \n2                            992.366638   \n3                           2246.017822   \n4                           2309.776123   \n\n   WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n0                                         110.047623                       \n1                                         329.366669                       \n2                                         248.166672                       \n3                                         329.342224                       \n4                                         284.576202                       \n\n   WORLDCLIM_BIO15_precipitation_seasonality  \\\n0                                  56.210766   \n1                                 109.906487   \n2                                 115.545128   \n3                                  56.563957   \n4                                  39.409706   \n\n   WORLDCLIM_BIO4_temperature_seasonality  \\\n0                              161.457764   \n1                              178.745422   \n2                              292.781219   \n3                              211.065521   \n4                               36.499138   \n\n   WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n0                                13.886666                            129   \n1                                19.846668                            139   \n2                                23.486668                            144   \n3                                16.768000                            116   \n4                                10.257143                            100   \n\n   SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  \\\n0                                141                              134   \n1                                140                              140   \n2                                143                              148   \n3                                132                              122   \n4                                113                              105   \n\n   SOIL_bdod_30.60cm_mean_0.01_deg  ...  VOD_X_1997_2018_multiyear_mean_m03  \\\n0                              137  ...                            0.452674   \n1                              137  ...                            0.448251   \n2                              144  ...                            0.491504   \n3                              129  ...                            0.548350   \n4                              111  ...                            0.645712   \n\n   VOD_X_1997_2018_multiyear_mean_m04  VOD_X_1997_2018_multiyear_mean_m05  \\\n0                            0.469246                            0.479971   \n1                            0.470133                            0.448403   \n2                            0.461915                            0.408343   \n3                            0.551841                            0.515061   \n4                            0.641703                            0.638654   \n\n   VOD_X_1997_2018_multiyear_mean_m06  VOD_X_1997_2018_multiyear_mean_m07  \\\n0                            0.488434                            0.495728   \n1                            0.405665                            0.382672   \n2                            0.365935                            0.338808   \n3                            0.555757                            0.525224   \n4                            0.647840                            0.647654   \n\n   VOD_X_1997_2018_multiyear_mean_m08  VOD_X_1997_2018_multiyear_mean_m09  \\\n0                            0.482645                            0.448959   \n1                            0.364023                            0.362919   \n2                            0.306375                            0.285225   \n3                            0.571438                            0.572420   \n4                            0.639092                            0.634200   \n\n   VOD_X_1997_2018_multiyear_mean_m10  VOD_X_1997_2018_multiyear_mean_m11  \\\n0                            0.419139                            0.404626   \n1                            0.368997                            0.391109   \n2                            0.289911                            0.337495   \n3                            0.566320                            0.556564   \n4                            0.628594                            0.644814   \n\n   VOD_X_1997_2018_multiyear_mean_m12  \n0                            0.403707  \n1                            0.407680  \n2                            0.393714  \n3                            0.512105  \n4                            0.654979  \n\n[5 rows x 163 columns]\n    X4_mean    X11_mean      X18_mean     X26_mean   X50_mean     X3112_mean\n0  1.035657  142.521015  19699.923668  3465.054691  15.842202  399384.490146\n1  0.980728  153.726248  19699.721088  3462.940457  14.456965  398961.220402\n2  1.373851  137.016532  19702.276217  3459.473270  15.833161  397614.158049\n3  0.790627  162.022021  19702.424188  3480.277051  14.684226  402414.611731\n4  1.004912  154.428170  19701.160757  3487.689253  15.023368  404405.289639\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot histograms for each trait\ntraits = labels.columns\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\naxes = axes.flatten()\n\nfor i, trait in enumerate(traits):\n    sns.histplot(labels[trait], kde=True, ax=axes[i])\n    axes[i].set_title(f'Distribution of {trait}')\n    axes[i].set_xlabel(trait)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = pd.DataFrame(ancillary_scaled, columns=ancillary_data.columns).corr()\nplt.figure(figsize=(12, 10))\nsns.heatmap(corr, cmap='coolwarm', annot=False, fmt='.2f')\nplt.title('Correlation Heatmap of Ancillary Features')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dot = Digraph()\n\ndot.node('A', 'Input: Image Features (CNN)')\ndot.node('B', 'Input: Ancillary Features')\ndot.node('C', 'Concatenate Features')\ndot.node('D', 'CatBoost Regressor')\ndot.node('E', 'Trait Predictions')\n\ndot.edges(['AC', 'BC', 'CD', 'DE'])\n\n# Save the diagram to a file\ndot.render('model_architecture', format='png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:21:24.753064Z","iopub.execute_input":"2024-08-13T10:21:24.753431Z","iopub.status.idle":"2024-08-13T10:21:24.778588Z","shell.execute_reply.started":"2024-08-13T10:21:24.753401Z","shell.execute_reply":"2024-08-13T10:21:24.777622Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the augmentation pipeline\naugmentation_pipeline = transforms.Compose([\n#     transforms.RandomHorizontalFlip(),\n#     transforms.RandomVerticalFlip(),\n#     transforms.ColorJitter(\n#         brightness=0.1,\n#         contrast=0.1,\n#         saturation=0.1\n#     ),\n    transforms.ToTensor(),\n#     transforms.Lambda(lambda x: x.clamp(0, 1))\n])\n\n# Example function to load and preprocess an image\ndef load_and_preprocess_image(image_path):\n    image = Image.open(image_path).convert('RGB')\n    image = augmentation_pipeline(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:21:16.141277Z","iopub.execute_input":"2024-08-13T10:21:16.142213Z","iopub.status.idle":"2024-08-13T10:21:16.147786Z","shell.execute_reply.started":"2024-08-13T10:21:16.142178Z","shell.execute_reply":"2024-08-13T10:21:16.146665Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained EfficientNet B7 model and move it to GPU\neffnet_model = efficientnet_b7(pretrained=True)\n\n# try using the last layer withour rthe pooling\n# effnet_model = torch.nn.Sequential(*list(effnet_model.children())[:-2], torch.nn.AdaptiveAvgPool2d((1, 1)))\neffnet_model = torch.nn.Sequential(*list(effnet_model.children())[:-1])\neffnet_model = effnet_model.to(device)  # Move the model to GPU","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:21:27.062077Z","iopub.execute_input":"2024-08-13T10:21:27.062468Z","iopub.status.idle":"2024-08-13T10:21:28.720679Z","shell.execute_reply.started":"2024-08-13T10:21:27.062438Z","shell.execute_reply":"2024-08-13T10:21:28.719902Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = load_and_preprocess_image(self.image_paths[idx])\n        return image\n\ndef extract_features_dataloader(dataloader):\n    features = []\n    effnet_model.eval()\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Extracting Features with DataLoader\"):\n            batch = batch.to(device)\n            batch_features = effnet_model(batch).flatten(start_dim=1)\n            features.append(batch_features.cpu().numpy())\n    return torch.tensor(np.concatenate(features, axis=0))","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:21:52.186916Z","iopub.execute_input":"2024-08-13T10:21:52.187809Z","iopub.status.idle":"2024-08-13T10:21:52.195278Z","shell.execute_reply.started":"2024-08-13T10:21:52.187775Z","shell.execute_reply":"2024-08-13T10:21:52.194155Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImageDataset(train_images)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\ntrain_image_features = extract_features_dataloader(train_dataloader)\n\nval_dataset = ImageDataset(val_images)\nval_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\nval_image_features = extract_features_dataloader(val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:21:55.669688Z","iopub.execute_input":"2024-08-13T10:21:55.670058Z","iopub.status.idle":"2024-08-13T10:24:10.590614Z","shell.execute_reply.started":"2024-08-13T10:21:55.670032Z","shell.execute_reply":"2024-08-13T10:24:10.589756Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Extracting Features with DataLoader: 100%|██████████| 1085/1085 [01:47<00:00, 10.08it/s]\nExtracting Features with DataLoader: 100%|██████████| 272/272 [00:27<00:00, 10.07it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming train_ancillary, train_image_features, and train_labels are already defined\nX_train_combined = np.concatenate([train_ancillary, train_image_features], axis=1)\nX_val_combined = np.concatenate([val_ancillary, val_image_features], axis=1)\n\n# Split data into training and validation sets\n# X_train, X_val, y_train, y_val = train_test_split(X_train_combined, train_labels, test_size=0.2, random_state=42)\n\n# Dictionary to store models and their training logs\nmodels = {}\ntraining_logs = {}\n\n# Train separate CatBoost models for each trait with GPU, early stopping, and multi-threading\nfor i, trait in tqdm(enumerate(labels.columns), total=len(labels.columns), desc=\"Training Models\"):\n    model = CatBoostRegressor(\n        iterations=500,  # Reduced iterations\n        depth=6,\n        learning_rate=0.1,\n        loss_function='RMSE',\n        task_type='GPU',  # Enable GPU training\n        early_stopping_rounds=50,  # Enable early stopping\n        thread_count=-1,  # Use all available CPU cores\n        logging_level='Verbose'  # Enable detailed logging\n    )\n    \n    # Create Pool for validation set\n#     train_pool = Pool(X_train, y_train.iloc[:, i])\n#     val_pool = Pool(X_val, y_val.iloc[:, i])\n    train_pool = Pool(X_train_combined, train_labels.iloc[:, i])\n    val_pool = Pool(X_val_combined, val_labels.iloc[:, i])\n    \n    # Fit the model\n    model.fit(train_pool, eval_set=val_pool, verbose=100)  # Adjust verbose as needed\n\n    # Store the model\n    models[trait] = model\n\n    # Store the training logs\n    training_logs[trait] = model.get_evals_result()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T10:24:13.945640Z","iopub.execute_input":"2024-08-13T10:24:13.946537Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Training Models:   0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"0:\tlearn: 0.1353396\ttest: 0.1363007\tbest: 0.1363007 (0)\ttotal: 4.75s\tremaining: 39m 30s\n100:\tlearn: 0.1186654\ttest: 0.1240133\tbest: 0.1240133 (100)\ttotal: 21.7s\tremaining: 1m 25s\n200:\tlearn: 0.1153299\ttest: 0.1235116\tbest: 0.1235116 (200)\ttotal: 38s\tremaining: 56.6s\n300:\tlearn: 0.1125424\ttest: 0.1232373\tbest: 0.1232262 (296)\ttotal: 54.3s\tremaining: 35.9s\n400:\tlearn: 0.1101331\ttest: 0.1230300\tbest: 0.1230207 (386)\ttotal: 1m 10s\tremaining: 17.4s\n","output_type":"stream"},{"name":"stderr","text":"Training Models:  17%|█▋        | 1/6 [02:27<12:17, 147.48s/it]","output_type":"stream"},{"name":"stdout","text":"499:\tlearn: 0.1079751\ttest: 0.1229340\tbest: 0.1229325 (494)\ttotal: 1m 26s\tremaining: 0us\nbestTest = 0.1229325277\nbestIteration = 494\nShrink model to first 495 iterations.\n0:\tlearn: 6.8150829\ttest: 6.8454593\tbest: 6.8454593 (0)\ttotal: 186ms\tremaining: 1m 32s\n100:\tlearn: 5.9354541\ttest: 6.1382688\tbest: 6.1382688 (100)\ttotal: 17.1s\tremaining: 1m 7s\n200:\tlearn: 5.7484638\ttest: 6.0997609\tbest: 6.0997609 (200)\ttotal: 33.7s\tremaining: 50.1s\n","output_type":"stream"}]},{"cell_type":"code","source":"# prev_logs = logs\n# print(prev_logs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training logs\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 10))\naxes = axes.flatten()\n\n# Create a subplot for each trait\nfor i, (trait, logs) in enumerate(training_logs.items()):\n    ax = axes[i]\n    \n    # Plot Train and Validation RMSE on the primary y-axis\n    ax.plot(logs['learn']['RMSE'], label='Train RMSE', color='blue')\n    ax.plot(logs['validation']['RMSE'], label='Validation RMSE', color='orange')\n    \n    ax.set_title(f'CatBoost Training for {trait}')\n    ax.set_xlabel('Iterations')\n    ax.set_ylabel('RMSE')\n    \n    # Create a secondary y-axis to plot overfitting\n    ax2 = ax.twinx()\n    overfitting = np.abs(np.array(logs['learn']['RMSE'][:220]) - np.array(logs['validation']['RMSE'][:220]))\n    ax.plot(overfitting, label='Overfitting |Train - Validation|, LR=0.01', color='red', linestyle='--')\n    ax.set_ylabel('Overfitting (RMSE Difference)')\n    \n    # Combine legends from both axes\n    lines, labels = ax.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n\n\nplt.tight_layout()\nplt.savefig('catboost.png')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\n# X_val_combined = np.concatenate([val_ancillary, val_image_features], axis=1)\n\nr2_scores = {}\nfor i, trait in tqdm(enumerate(val_labels.columns), total=len(val_labels.columns), desc=\"Validating Models\"):\n    y_pred = models[trait].predict(X_val_combined)  # Predictions use GPU if CatBoost model was trained on GPU\n    r2_scores[trait] = r2_score(val_labels.iloc[:, i], y_pred)\n\nprint(\"R2 Scores:\", r2_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntest_data = pd.read_csv('/kaggle/working/data/test.csv')\n\nancillary_columns = test_data.columns[1:164]\nprint(ancillary_columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split features and targets\ntest_image_paths = 'data/test_images/' + test_data.iloc[:, 0].astype(str) + '.jpeg'\n\ntest_ancillary_data = test_data.iloc[:, 1:164]\ntest_labels = test_data.iloc[:, 164:]\n\ntest_image_paths = test_image_paths.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate predictions for the test set\ntest_dataset = ImageDataset(test_image_paths)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\ntest_image_features = extract_features_dataloader(test_dataloader)  # Define test_image_paths\n\nX_test_combined = np.concatenate([test_ancillary_data, test_image_features], axis=1)\n\ntest_ids = test_data['id'].values  # Extract test IDs from the test dataset\n\nsubmission = pd.DataFrame({'id': test_ids})  # Define test_ids\nfor trait in models:\n    submission[trait] = models[trait].predict(X_test_combined)\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}